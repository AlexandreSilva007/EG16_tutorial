{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "Install Theano and Lasagne using the following commands:\n",
    "\n",
    "```\n",
    "pip install -r https://raw.githubusercontent.com/Lasagne/Lasagne/master/requirements.txt\n",
    "pip install https://github.com/Lasagne/Lasagne/archive/master.zip\n",
    "```\n",
    "\n",
    "Working in a virtual environment is recommended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "Current code allows to generate geodesic patches from a collection of shapes represented as triangular meshes.\n",
    "To get started with the pre-processing:\n",
    "```\n",
    "git clone https://github.com/jonathanmasci/ShapeNet_data_preparation_toolbox.git\n",
    "```\n",
    "\n",
    "The usual processing pipeline is show in ```run_forrest_run.m```. \n",
    "We will soon update this preparation stage, so perhaps better to start with our pre-computed dataset, and stay tuned! :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepared data\n",
    "\n",
    "All it is required to train on the FAUST_registration dataset for this demo is available for download at\n",
    "https://www.dropbox.com/s/aamd98nynkvbcop/EG16_tutorial.tar.bz2?dl=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICNN Toolbox\n",
    "\n",
    "```\n",
    "git clone https://github.com/jonathanmasci/EG16_tutorial.git\n",
    "```\n",
    "\n",
    "![](http://www.people.usi.ch/mascij/EG16_tutorial/shapenet_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN Black (CNMeM is disabled, CuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import time\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import theano.sparse as Tsp\n",
    "\n",
    "import lasagne as L\n",
    "import lasagne.layers as LL\n",
    "import lasagne.objectives as LO\n",
    "from lasagne.layers.normalization import batch_norm\n",
    "\n",
    "sys.path.append('..')\n",
    "from icnn import utils_lasagne, dataset, snapshotter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train descs\n",
      "elapsed time 8.800258\n",
      "Loading test descs\n",
      "elapsed time 2.055301\n",
      "Loading train patches\n",
      "elapsed time 32.164742\n",
      "Loading test patches\n",
      "elapsed time 8.138161\n",
      "Loading train labels\n",
      "elapsed time 0.253714\n",
      "Loading test labels\n",
      "elapsed time 0.049056\n"
     ]
    }
   ],
   "source": [
    "base_path = '/media/nas/EG16_tutorial/dataset/FAUST_registrations/data/diam=200/'\n",
    "\n",
    "ds = dataset.ClassificationDatasetPatchesMinimal(\n",
    "    'FAUST_registrations_train.txt', 'FAUST_registrations_test.txt',\n",
    "    os.path.join(base_path, 'descs', 'shot'),\n",
    "    os.path.join(base_path, 'patch_aniso', 'alpha=100_nangles=016_ntvals=005_tmin=6.000_tmax=24.000_thresh=99.900_norm=L1'), \n",
    "    None, \n",
    "    os.path.join(base_path, 'labels'),\n",
    "    epoch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nin = 544\n",
    "nclasses = 6890\n",
    "l2_weight = 1e-5\n",
    "\n",
    "def get_model(inp, patch_op):\n",
    "    icnn = LL.DenseLayer(inp, 16)\n",
    "    icnn = batch_norm(utils_lasagne.GCNNLayer([icnn, patch_op], 16, nrings=5, nrays=16))\n",
    "#     icnn = batch_norm(utils_lasagne.GCNNLayer([icnn, patch_op], 32, nrings=5, nrays=16))\n",
    "#     icnn = batch_norm(utils_lasagne.GCNNLayer([icnn, patch_op], 64, nrings=5, nrays=16))\n",
    "#     ffn = batch_norm(LL.DenseLayer(icnn, 512))\n",
    "    ffn = LL.DenseLayer(icnn, nclasses, nonlinearity=utils_lasagne.log_softmax)\n",
    "\n",
    "    return ffn\n",
    "\n",
    "inp = LL.InputLayer(shape=(None, nin))\n",
    "patch_op = LL.InputLayer(input_var=Tsp.csc_fmatrix('patch_op'), shape=(None, None))\n",
    "\n",
    "ffn = get_model(inp, patch_op)\n",
    "\n",
    "# L.layers.get_output -> theano variable representing network\n",
    "output = LL.get_output(ffn)\n",
    "pred = LL.get_output(ffn, deterministic=True)  # in case we use dropout\n",
    "\n",
    "# target theano variable indicatind the index a vertex should be mapped to wrt the latent space\n",
    "target = T.ivector('idxs')\n",
    "\n",
    "# to work with logit predictions, better behaved numerically\n",
    "cla = utils_lasagne.categorical_crossentropy_logdomain(output, target, nclasses).mean()\n",
    "acc = LO.categorical_accuracy(pred, target).mean()\n",
    "\n",
    "# a bit of regularization is commonly used\n",
    "regL2 = L.regularization.regularize_network_params(ffn, L.regularization.l2)\n",
    "\n",
    "\n",
    "cost = cla + l2_weight * regL2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the update rule, how to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = LL.get_all_params(ffn, trainable=True)\n",
    "grads = T.grad(cost, params)\n",
    "# computes the L2 norm of the gradient to better inspect training\n",
    "grads_norm = T.nlinalg.norm(T.concatenate([g.flatten() for g in grads]), 2)\n",
    "\n",
    "# Adam turned out to be a very good choice for correspondence\n",
    "updates = L.updates.adam(grads, params, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "funcs = dict()\n",
    "funcs['train'] = theano.function([inp.input_var, patch_op.input_var, target],\n",
    "                                 [cost, cla, l2_weight * regL2, grads_norm, acc], updates=updates,\n",
    "                                 on_unused_input='warn')\n",
    "funcs['acc_loss'] = theano.function([inp.input_var, patch_op.input_var, target],\n",
    "                                    [acc, cost], on_unused_input='warn')\n",
    "funcs['predict'] = theano.function([inp.input_var, patch_op.input_var],\n",
    "                                   [pred], on_unused_input='warn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training (simplified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 000][trn] cost  8.686162 (cla 8.6846, reg 0.0016), |grad| = 0.065082, acc = 0.13498 % (28.90sec)\n",
      "           [tst] cost  8.484253, acc = 0.28882 %\n",
      "[Epoch 001][trn] cost  8.263211 (cla 8.2573, reg 0.0059), |grad| = 0.153099, acc = 0.44354 % (29.20sec)\n",
      "           [tst] cost  8.047215, acc = 0.60160 %"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:[KVP] Overwriting group best_train_params!\n",
      "ERROR:root:[KVP] Overwriting group best_test_params!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-4f11d2d24f2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mb_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_r\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_g\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mx_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfuncs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# do some book keeping (store stuff for training curves etc)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mascij/work/sw/Theano/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/mascij/work/sw/Theano/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    911\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 913\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    914\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "eval_freq = 1\n",
    "\n",
    "start_time = time.time()\n",
    "best_trn = 1e5\n",
    "best_tst = 1e5\n",
    "\n",
    "kvs = snapshotter.Snapshotter('demo_training.snap')\n",
    "\n",
    "for it_count in xrange(n_epochs):\n",
    "    tic = time.time()\n",
    "    b_l, b_c, b_s, b_r, b_g, b_a = [], [], [], [], [], []\n",
    "    for x_ in ds.train_iter():\n",
    "        tmp = funcs['train'](*x_)\n",
    "\n",
    "        # do some book keeping (store stuff for training curves etc)\n",
    "        b_l.append(tmp[0])\n",
    "        b_c.append(tmp[1])\n",
    "        b_r.append(tmp[2])\n",
    "        b_g.append(tmp[3])\n",
    "        b_a.append(tmp[4])\n",
    "    epoch_cost = np.asarray([np.mean(b_l), np.mean(b_c), np.mean(b_r), np.mean(b_g), np.mean(b_a)])\n",
    "    print(('[Epoch %03i][trn] cost %9.6f (cla %6.4f, reg %6.4f), |grad| = %.06f, acc = %7.5f %% (%.2fsec)') %\n",
    "                 (it_count, epoch_cost[0], epoch_cost[1], epoch_cost[2], epoch_cost[3], epoch_cost[4] * 100, \n",
    "                  time.time() - tic))\n",
    "\n",
    "    if np.isnan(epoch_cost[0]):\n",
    "        print(\"NaN in the loss function...let's stop here\")\n",
    "        break\n",
    "\n",
    "    if (it_count % eval_freq) == 0:\n",
    "        v_c, v_a = [], []\n",
    "        for x_ in ds.test_iter():\n",
    "            tmp = funcs['acc_loss'](*x_)\n",
    "            v_a.append(tmp[0])\n",
    "            v_c.append(tmp[1])\n",
    "        test_cost = [np.mean(v_c), np.mean(v_a)]\n",
    "        print(('           [tst] cost %9.6f, acc = %7.5f %%') % (test_cost[0], test_cost[1] * 100))\n",
    "\n",
    "        if epoch_cost[0] < best_trn:\n",
    "            kvs.store('best_train_params', [it_count, LL.get_all_param_values(ffn)])\n",
    "            best_trn = epoch_cost[0]\n",
    "        if test_cost[0] < best_tst:\n",
    "            kvs.store('best_test_params', [it_count, LL.get_all_param_values(ffn)])\n",
    "            best_tst = test_cost[0]\n",
    "print(\"...done training %f\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test phase\n",
    "Now that the model is train it is enough to take the fwd function and apply it to new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rewrite = True\n",
    "\n",
    "out_path = '/tmp/EG16_tutorial/dumps/' \n",
    "print \"Saving output to: %s\" % out_path\n",
    "\n",
    "if not os.path.isdir(out_path) or rewrite==True:\n",
    "    try:\n",
    "        os.makedirs(out_path)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    a = []\n",
    "    for i,d in enumerate(ds.test_iter()):\n",
    "        fname = os.path.join(out_path, \"%s\" % ds.test_fnames[i])\n",
    "        print fname,\n",
    "        tmp = funcs['predict'](d[0], d[1])[0]\n",
    "        a.append(np.mean(np.argmax(tmp, axis=1).flatten() == d[2].flatten()))\n",
    "        scipy.io.savemat(fname, {'desc': tmp})\n",
    "        print \", Acc: %7.5f %%\" % (a[-1] * 100.0)\n",
    "    print \"\\nAverage accuracy across all shapes: %7.5f %%\" % (np.mean(a) * 100.0)\n",
    "else:\n",
    "    print \"Model predictions already produced.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://www.people.usi.ch/mascij/EG16_tutorial/shapenet_corr.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
